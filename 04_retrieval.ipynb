{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da0bf508",
   "metadata": {},
   "source": [
    "# Retrieval\n",
    "\n",
    "Retrieval is the centerpiece of our retrieval augmented generation (RAG) flow. \n",
    "\n",
    "Let's get our vectorDB from before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d29e360",
   "metadata": {},
   "source": [
    "## Vectorstore retrieval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c04d306b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e224e523",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install lark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3405dbdc",
   "metadata": {},
   "source": [
    "### Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3602a05f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "persist_directory = 'data/chroma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "731bd6a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e94d7e20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c2525af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"\"\"The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).\"\"\",\n",
    "    \"\"\"A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.\"\"\",\n",
    "    \"\"\"A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.\"\"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8506e8c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "smalldb = Chroma.from_texts(texts, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2a481c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"Tell me about all-white mushrooms with large fruiting bodies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e98cd531",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.'),\n",
       " Document(page_content='The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smalldb.similarity_search(question, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "204970d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.'),\n",
       " Document(page_content='A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smalldb.max_marginal_relevance_search(question, k=2, fetch_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72e5858",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Addressing Diversity: Maximum marginal relevance\n",
    "\n",
    "Last class we introduced one problem: how to enforce diversity in the search results.\n",
    " \n",
    "`Maximum marginal relevance` strives to achieve both relevance to the query *and diversity* among the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "589b246b",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "docs_ss = vectordb.similarity_search(question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "057b0689",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'those homeworks will be done in either MATLA B or in Octave, which is sort of — I \\nknow some people '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_ss[0].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc4201bb",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'those homeworks will be done in either MATLA B or in Octave, which is sort of — I \\nknow some people '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_ss[1].page_content[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0259473",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note the difference in results with `MMR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b38a45fc",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs_mmr = vectordb.max_marginal_relevance_search(question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1008c89a",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'those homeworks will be done in either MATLA B or in Octave, which is sort of — I \\nknow some people '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_mmr[0].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88d17b71",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"mathematical work, he feels like he's disc overing truth and beauty in the universe. And \\nhe says it\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_mmr[1].page_content[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedba3c9",
   "metadata": {},
   "source": [
    "### Addressing Specificity: working with metadata\n",
    "\n",
    "In last lecture, we showed that a question about the third lecture can include results from other lectures as well.\n",
    "\n",
    "To address this, many vectorstores support operations on `metadata`.\n",
    "\n",
    "`metadata` provides context for each embedded chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37df368e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"what did they say about regression in the third lecture?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5516326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['05e62b88-9108-459f-b0d1-e4afa79a00e3',\n",
       " '060b7504-6232-4137-971f-71a4830bf21d',\n",
       " '08f77f5d-f7cd-4c28-9734-03e434097c63',\n",
       " '099fdeeb-bdd5-4e8c-8d59-132e596d4be9',\n",
       " '09ed7880-1b8a-4f48-a1a9-adc43e6a8a0a',\n",
       " '0c7f63ba-0a54-4322-9295-3f967b97cf99',\n",
       " '0db3aa8e-9f6b-41c6-8766-91b9c90de279',\n",
       " '0e73eeea-9ed8-4f10-92d4-ce343fc362e6',\n",
       " '0f4d63dc-b1d4-4e41-9365-36d654822c9c',\n",
       " '10001f09-8289-49e9-acca-3a6b98bd792d']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDS = vectordb._collection.peek()['ids']\n",
    "IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8fefe536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['05e62b88-9108-459f-b0d1-e4afa79a00e3'],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [{'page': 6, 'source': 'data/MachineLearning-Lecture01.pdf'}],\n",
       " 'documents': [\"to happen.  \\nThe section here on the late homework polic y if you ever want to hand in a homework \\nlate, I'll leave you to r ead that yourself.  \\nWe also have a midterm, which is scheduled for Thursday, 8th of November at 6:00 p.m., \\nso please keep that evening free.  \\nAnd let's see. And one more administrative thing I wanted to sa y is about the class \\nproject. So part of the goal of this cla ss is to leave you well eq uipped to apply machine \\nlearning algorithms to a problem or to do rese arch in machine learning. And so as part of \\nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \\nAnd what most students do for this is either  apply machine learning to a problem that you \\nfind interesting or investigate some aspect of  machine learning. So to those of you that \\nare either already doing research or to those of you who are in industry, you're taking this \\nfrom a company, one fantastic sort of way to do a class project would be if you apply \\nmachine learning algorithms to a problem that  you're interested in, to a problem that \\nyou're already working on, whether it be a scien ce research problem or sort of a problem \\nin industry where you're trying to get a syst em to work using a learning algorithm.  \\nTo those of you that are not currently doing re search, one great way to do a project would \\nbe if you apply learning algorithms to just pick a problem that you care about. Pick a\"],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': ['metadatas', 'documents']}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb._collection.get(IDS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2c5e4b75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(\n",
    "    question,\n",
    "    k=3,\n",
    "    filter={\"source\":\"data/MachineLearning-Lecture03.pdf\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89ba7434",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 0, 'source': 'data/MachineLearning-Lecture03.pdf'}\n",
      "{'page': 14, 'source': 'data/MachineLearning-Lecture03.pdf'}\n",
      "{'page': 6, 'source': 'data/MachineLearning-Lecture03.pdf'}\n"
     ]
    }
   ],
   "source": [
    "for d in docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc23757",
   "metadata": {},
   "source": [
    "### Addressing Specificity: working with metadata using self-query retriever\n",
    "\n",
    "But we have an interesting challenge: we often want to infer the metadata from the query itself.\n",
    "\n",
    "To address this, we can use `SelfQueryRetriever`, which uses an LLM to extract:\n",
    " \n",
    "1. The `query` string to use for vector search\n",
    "2. A metadata filter to pass in as well\n",
    "\n",
    "Most vector databases support metadata filters, so this doesn't require any new databases or indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d423553f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "01790d6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"\"\"The lecture the chunk is from, should be one of \n",
    "        `data/MachineLearning-Lecture01.pdf`,\n",
    "        `data/MachineLearning-Lecture02.pdf`, or\n",
    "        `data/MachineLearning-Lecture03.pdf`\"\"\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"The page from the lecture\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1a5302",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Note:** The default model for `OpenAI` (\"from langchain.llms import OpenAI\") is `text-davinci-003`. Due to the deprication of OpenAI's model `text-davinci-003` on 4 January 2024, you'll be using OpenAI's recommended replacement model `gpt-3.5-turbo-instruct` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a49b753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SelfQueryRetriever?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "62454484",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "document_content_description = \"Lecture notes\"\n",
    "llm = OpenAI(model='gpt-3.5-turbo-instruct', temperature=0)\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectordb,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "91385085",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"what did they say about regression in the third lecture?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd22b78d",
   "metadata": {},
   "source": [
    "**You will receive a warning** about predict_and_parse being deprecated the first time you executing the next line. This can be safely ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "65e918b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9d445f8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 2, 'source': 'data/MachineLearning-Lecture03.pdf'}\n",
      "{'page': 10, 'source': 'data/MachineLearning-Lecture03.pdf'}\n",
      "{'page': 11, 'source': 'data/MachineLearning-Lecture03.pdf'}\n",
      "{'page': 6, 'source': 'data/MachineLearning-Lecture03.pdf'}\n"
     ]
    }
   ],
   "source": [
    "for d in docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0245060",
   "metadata": {},
   "source": [
    "### Additional tricks: compression\n",
    "\n",
    "Another approach for improving the quality of retrieved docs is compression.\n",
    "\n",
    "Information most relevant to a query may be buried in a document with a lot of irrelevant text. \n",
    "\n",
    "Passing that full document through your application can lead to more expensive LLM calls and poorer responses.\n",
    "\n",
    "Contextual compression is meant to fix this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aea78f59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "340170fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1621b066",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Wrap our vectorstore\n",
    "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo-instruct\")\n",
    "compressor = LLMChainExtractor.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a001e2bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "68ff6b4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "- \"those homeworks will be done in either MATLA B or in Octave\"\n",
      "- \"I know some people call it a free ve rsion of MATLAB\"\n",
      "- \"MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data.\"\n",
      "- \"there's also a software package called Octave that you can download for free off the Internet.\"\n",
      "- \"it has somewhat fewer features than MATLAB, but it's free, and for the purposes of this class, it will work for just about everything.\"\n",
      "- \"once a colleague of mine at a different university, not at Stanford, actually teaches another machine learning course.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "- \"those homeworks will be done in either MATLA B or in Octave\"\n",
      "- \"I know some people call it a free ve rsion of MATLAB\"\n",
      "- \"MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data.\"\n",
      "- \"there's also a software package called Octave that you can download for free off the Internet.\"\n",
      "- \"it has somewhat fewer features than MATLAB, but it's free, and for the purposes of this class, it will work for just about everything.\"\n",
      "- \"once a colleague of mine at a different university, not at Stanford, actually teaches another machine learning course.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "\"Oh, it was the MATLAB.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "\"Oh, it was the MATLAB.\"\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dad5829a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf6c26d",
   "metadata": {},
   "source": [
    "## Combining various techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ece8797",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever(search_type = \"mmr\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e40214",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f82151",
   "metadata": {},
   "source": [
    "## Other types of retrieval\n",
    "\n",
    "It's worth noting that vectordb as not the only kind of tool to retrieve documents. \n",
    "\n",
    "The `LangChain` retriever abstraction includes other ways to retrieve documents, such as TF-IDF or SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1c8a9b68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers import SVMRetriever\n",
    "from langchain.retrievers import TFIDFRetriever\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3bf65c47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load PDF\n",
    "loader = PyPDFLoader(\"data/MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()\n",
    "all_page_text=[p.page_content for p in pages]\n",
    "joined_page_text=\" \".join(all_page_text)\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1500,chunk_overlap = 150)\n",
    "splits = text_splitter.split_text(joined_page_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ab4db671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ae4651f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rauna\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# Retrieve\n",
    "svm_retriever = SVMRetriever.from_texts(splits, embedding)\n",
    "tfidf_retriever = TFIDFRetriever.from_texts(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "53bd69a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"or find project partners or discuss homework problems and so on, and it's not monitored \\nby the TAs and me. So feel free to ta lk trash about this class there.  \\nIf you want to contact the teaching staff, pl ease use the email address written down here, \\ncs229-qa@cs.stanford.edu. This goes to an acc ount that's read by all the TAs and me. So \\nrather than sending us email individually, if you send email to this account, it will \\nactually let us get back to you maximally quickly with answers to your questions.  \\nIf you're asking questions about homework probl ems, please say in the subject line which \\nassignment and which question the email refers to, since that will also help us to route \\nyour question to the appropriate TA or to me  appropriately and get the response back to \\nyou quickly.  \\nLet's see. Skipping ahead — let's see — for homework, one midterm, one open and term \\nproject. Notice on the honor code. So one thi ng that I think will help you to succeed and \\ndo well in this class and even help you to enjoy this cla ss more is if you form a study \\ngroup.  \\nSo start looking around where you' re sitting now or at the end of class today, mingle a \\nlittle bit and get to know your classmates. I strongly encourage you to form study groups \\nand sort of have a group of people to study with and have a group of your fellow students \\nto talk over these concepts with. You can also  post on the class news group if you want to \\nuse that to try to form a study group.\")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are major topics for this class?\"\n",
    "docs_svm=svm_retriever.get_relevant_documents(question)\n",
    "docs_svm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8ef3e11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "or find project partners or discuss homework problems and so on, and it's not monitored \n",
      "by the TAs and me. So feel free to ta lk trash about this class there.  \n",
      "If you want to contact the teaching staff, pl ease use the email address written down here, \n",
      "cs229-qa@cs.stanford.edu. This goes to an acc ount that's read by all the TAs and me. So \n",
      "rather than sending us email individually, if you send email to this account, it will \n",
      "actually let us get back to you maximally quickly with answers to your questions.  \n",
      "If you're asking questions about homework probl ems, please say in the subject line which \n",
      "assignment and which question the email refers to, since that will also help us to route \n",
      "your question to the appropriate TA or to me  appropriately and get the response back to \n",
      "you quickly.  \n",
      "Let's see. Skipping ahead — let's see — for homework, one midterm, one open and term \n",
      "project. Notice on the honor code. So one thi ng that I think will help you to succeed and \n",
      "do well in this class and even help you to enjoy this cla ss more is if you form a study \n",
      "group.  \n",
      "So start looking around where you' re sitting now or at the end of class today, mingle a \n",
      "little bit and get to know your classmates. I strongly encourage you to form study groups \n",
      "and sort of have a group of people to study with and have a group of your fellow students \n",
      "to talk over these concepts with. You can also  post on the class news group if you want to \n",
      "use that to try to form a study group.\n"
     ]
    }
   ],
   "source": [
    "print(docs_svm[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d7bbb046",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"Saxena and Min Sun here did, wh ich is given an image like this, right? This is actually a \\npicture taken of the Stanford campus. You can apply that sort of cl ustering algorithm and \\ngroup the picture into regions. Let me actually blow that up so that you can see it more \\nclearly. Okay. So in the middle, you see the lines sort of groupi ng the image together, \\ngrouping the image into [inaudible] regions.  \\nAnd what Ashutosh and Min did was they then  applied the learning algorithm to say can \\nwe take this clustering and us e it to build a 3D model of the world? And so using the \\nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \\nworld looks like so that they could come up with a 3D model that you can sort of fly \\nthrough, okay? Although many people used to th ink it's not possible to take a single \\nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \\nalgorithm is the first step. They were able to.  \\nI'll just show you one more example. I like this  because it's a picture of Stanford with our \\nbeautiful Stanford campus. So again, taking th e same sort of clustering algorithms, taking \\nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \\nregions. And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.  You can sort of walk  into the ceiling, look\")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "docs_tfidf=tfidf_retriever.get_relevant_documents(question)\n",
    "docs_tfidf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "683ee57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saxena and Min Sun here did, wh ich is given an image like this, right? This is actually a \n",
      "picture taken of the Stanford campus. You can apply that sort of cl ustering algorithm and \n",
      "group the picture into regions. Let me actually blow that up so that you can see it more \n",
      "clearly. Okay. So in the middle, you see the lines sort of groupi ng the image together, \n",
      "grouping the image into [inaudible] regions.  \n",
      "And what Ashutosh and Min did was they then  applied the learning algorithm to say can \n",
      "we take this clustering and us e it to build a 3D model of the world? And so using the \n",
      "clustering, they then had a lear ning algorithm try to learn what the 3D structure of the \n",
      "world looks like so that they could come up with a 3D model that you can sort of fly \n",
      "through, okay? Although many people used to th ink it's not possible to take a single \n",
      "image and build a 3D model, but using a lear ning algorithm and that sort of clustering \n",
      "algorithm is the first step. They were able to.  \n",
      "I'll just show you one more example. I like this  because it's a picture of Stanford with our \n",
      "beautiful Stanford campus. So again, taking th e same sort of clustering algorithms, taking \n",
      "the same sort of unsupervised learning algor ithm, you can group the pixels into different \n",
      "regions. And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.  You can sort of walk  into the ceiling, look\n"
     ]
    }
   ],
   "source": [
    "print(docs_tfidf[0].page_content)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
